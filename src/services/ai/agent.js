const OpenAI = require('openai');
const Anthropic = require('@anthropic-ai/sdk');
const logger = require('../../utils/logger');
const marketplaceSearch = require('../search/marketplaceSearch');

/**
 * Detect language from text message
 * Returns 'ar' if Arabic characters are detected, 'en' otherwise
 * @param {string} text - Text to analyze
 * @returns {string} - 'ar' or 'en'
 */
function detectLanguage(text) {
  if (!text || typeof text !== 'string') {
    return 'ar'; // Default to Arabic
  }
  
  // Check for Arabic characters (Unicode range: \u0600-\u06FF)
  const arabicPattern = /[\u0600-\u06FF]/;
  const hasArabic = arabicPattern.test(text);
  
  // Count Arabic vs English characters
  const arabicChars = (text.match(/[\u0600-\u06FF]/g) || []).length;
  const englishChars = (text.match(/[a-zA-Z]/g) || []).length;
  
  // If Arabic characters are present and more than 30% of the text, consider it Arabic
  if (hasArabic && arabicChars > text.length * 0.1) {
    return 'ar';
  }
  
  // If mostly English characters, consider it English
  if (englishChars > text.length * 0.5) {
    return 'en';
  }
  
  // Default to Arabic if uncertain
  return 'ar';
}

class AIAgent {
  constructor() {
    this.openai = process.env.OPENAI_API_KEY ? new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    }) : null;

    this.anthropic = process.env.ANTHROPIC_API_KEY ? new Anthropic({
      apiKey: process.env.ANTHROPIC_API_KEY
    }) : null;

    this.provider = process.env.AI_PROVIDER || 'openai'; // 'openai' or 'anthropic'
    
    // Model configuration - use environment variable or fallback to accessible models
    this.openaiModel = process.env.OPENAI_MODEL || 'gpt-5-mini'; // Default to gpt-5-mini (more accessible)
    this.anthropicModel = process.env.ANTHROPIC_MODEL || 'claude-3-5-sonnet-20241022';
    
    console.log('ü§ñ [AI] AI Agent initialized:', {
      provider: this.provider,
      openaiModel: this.openaiModel,
      anthropicModel: this.anthropicModel,
      hasOpenAI: !!this.openai,
      hasAnthropic: !!this.anthropic
    });
  }

  /**
   * Analyze message and extract search parameters
   * @param {string} message - User message
   * @param {string} language - Message language (ar/en)
   * @returns {Promise<Object>} Extracted search parameters
   */
  async analyzeMessage(message, language = 'ar') {
    try {
      console.log('ü§ñ [AI-ANALYZE] Starting analysis...');
      console.log('üì• [AI-ANALYZE] Input:', {
        message: message,
        language: language,
        provider: this.provider
      });
      
      // Step 1: Fetch root categories first
      console.log('üìÇ [AI-ANALYZE] Fetching root categories...');
      let categories = [];
      try {
        categories = await marketplaceSearch.getCategories();
        console.log('‚úÖ [AI-ANALYZE] Categories fetched:', categories.length, 'categories');
        console.log('üìã [AI-ANALYZE] Available categories:', categories.map(c => ({
          slug: c.slug,
          nameEn: c.nameEn,
          nameAr: c.nameAr
        })));
      } catch (categoryError) {
        console.warn('‚ö†Ô∏è  [AI-ANALYZE] Failed to fetch categories, continuing without category validation:', categoryError.message);
      }
      
      // Detect language from message if not provided
      const detectedLanguage = language || detectLanguage(message);
      console.log('üåê [AI-ANALYZE] Language detection:', {
        provided: language,
        detected: detectedLanguage,
        message_preview: message.substring(0, 50)
      });
      
      // Build category list for AI prompt
      // Note: API returns 'name' field which is in the requested language (ar/en)
      let categoryList = '';
      if (categories.length > 0) {
        const categoryNames = categories.map(cat => {
          // Use 'name' field which is already in the correct language
          const name = cat.name || cat.nameAr || cat.nameEn || cat.slug;
          return `- ${cat.slug} (${name})`;
        }).join('\n');
        categoryList = `\n\nAvailable categories (use the exact slug):\n${categoryNames}\n\nIMPORTANT: You MUST use one of these exact category slugs. If the user's intent doesn't match any category, set category to null.`;
      } else {
        categoryList = '\n\nCommon categories: vehicles, real-estate, electronics, furniture, fashion, services';
      }
      
      const systemPrompt = `You are an AI assistant helping users search for items on kasioon.com marketplace in Syria.${categoryList}

IMPORTANT: The user's message is in ${detectedLanguage === 'ar' ? 'Arabic' : 'English'}. Extract search parameters from the user's message and return them in JSON format.

Extract the following parameters if mentioned:
- city: The city where they want to search (e.g., Aleppo, Damascus, Homs, Latakia)
- category: Main category slug (MUST match one of the available category slugs exactly, or null if no match)
- keywords: General search keywords (extract from user message)
- minPrice: Minimum price
- maxPrice: Maximum price
- condition: Item condition (new, used)

For vehicles specifically, also extract:
- carBrand: Car brand/make (e.g., Toyota, BMW, Mercedes)
- carModel: Specific car model (e.g., Corolla, Camry, 320i)
- minYear: Minimum year
- maxYear: Maximum year
- fuelType: Fuel type (petrol, diesel, electric, hybrid)
- transmission: Transmission type (manual, automatic)

Return ONLY a valid JSON object with the extracted parameters. If a parameter is not mentioned, omit it. The category field MUST be one of the available category slugs or null.

Examples:
User: "ÿ£ÿ±ŸäÿØ ÿ≥Ÿäÿßÿ±ÿ© ÿ™ŸàŸäŸàÿ™ÿß ŸÅŸä ÿ≠ŸÑÿ®"
Response: {"city": "Aleppo", "category": "vehicles", "carBrand": "Toyota", "keywords": "ÿ≥Ÿäÿßÿ±ÿ© ÿ™ŸàŸäŸàÿ™ÿß"}

User: "ÿ¥ŸÇÿ© ŸÑŸÑÿ®Ÿäÿπ ŸÅŸä ÿØŸÖÿ¥ŸÇ"
Response: {"city": "Damascus", "category": "real-estate", "keywords": "ÿ¥ŸÇÿ© ŸÑŸÑÿ®Ÿäÿπ"}

User: "ŸÑÿßÿ®ÿ™Ÿàÿ® ŸÖÿ≥ÿ™ÿπŸÖŸÑ"
Response: {"category": "electronics", "keywords": "ŸÑÿßÿ®ÿ™Ÿàÿ®", "condition": "used"}`;

      let extractedParams;

      if (this.provider === 'anthropic' && this.anthropic) {
        console.log('üîµ [AI-ANALYZE] Using Anthropic Claude...');
        console.log('ü§ñ [AI-ANALYZE] Model:', this.anthropicModel);
        const response = await this.anthropic.messages.create({
          model: this.anthropicModel,
          max_tokens: 1024,
          messages: [
            {
              role: 'user',
              content: `${systemPrompt}\n\nUser message: "${message}"`
            }
          ]
        });

        console.log('‚úÖ [AI-ANALYZE] Anthropic response received');
        const content = response.content[0].text;
        console.log('üìÑ [AI-ANALYZE] Raw response:', content);
        extractedParams = JSON.parse(content);

      } else if (this.openai) {
        console.log('üü¢ [AI-ANALYZE] Using OpenAI GPT...');
        console.log('ü§ñ [AI-ANALYZE] Model:', this.openaiModel);
        
        try {
          // Build request parameters
          const requestParams = {
            model: this.openaiModel,
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: message }
            ],
            response_format: { type: 'json_object' }
          };
          
          // Some models (like gpt-5-nano) don't support custom temperature
          // Only add temperature if model supports it
          const modelsWithoutTemperature = ['gpt-5-nano'];
          if (!modelsWithoutTemperature.includes(this.openaiModel)) {
            requestParams.temperature = 0.3;
          } else {
            console.log('‚ö†Ô∏è  [AI-ANALYZE] Model does not support custom temperature, using default');
          }
          
          const response = await this.openai.chat.completions.create(requestParams);

          console.log('‚úÖ [AI-ANALYZE] OpenAI response received');
          const rawContent = response.choices[0].message.content;
          console.log('üìÑ [AI-ANALYZE] Raw response:', rawContent);
          extractedParams = JSON.parse(rawContent);
        } catch (modelError) {
          // Check if it's a temperature error - retry without temperature
          if (modelError.message && modelError.message.includes('temperature') && 
              (modelError.message.includes('does not support') || modelError.message.includes('Unsupported value'))) {
            console.warn('‚ö†Ô∏è  [AI-ANALYZE] Temperature not supported, retrying without temperature...');
            try {
              const response = await this.openai.chat.completions.create({
                model: this.openaiModel,
                messages: [
                  { role: 'system', content: systemPrompt },
                  { role: 'user', content: message }
                ],
                response_format: { type: 'json_object' }
                // No temperature parameter
              });
              
              console.log('‚úÖ [AI-ANALYZE] Retry without temperature succeeded!');
              const rawContent = response.choices[0].message.content;
              console.log('üìÑ [AI-ANALYZE] Raw response:', rawContent);
              extractedParams = JSON.parse(rawContent);
            } catch (retryError) {
              console.error('‚ùå [AI-ANALYZE] Retry also failed:', retryError.message);
              throw modelError; // Throw original error
            }
          }
          // If model access error, try fallback models
          else if (modelError.message && modelError.message.includes('does not have access to model')) {
            console.warn('‚ö†Ô∏è  [AI-ANALYZE] Model access error, trying fallback models...');
            const fallbackModels = ['gpt-5-mini', 'gpt-3.5-turbo', 'gpt-4'];
            
            for (const fallbackModel of fallbackModels) {
              if (fallbackModel === this.openaiModel) continue; // Skip if already tried
              
              try {
                console.log(`üîÑ [AI-ANALYZE] Trying fallback model: ${fallbackModel}`);
                
                const fallbackParams = {
                  model: fallbackModel,
                  messages: [
                    { role: 'system', content: systemPrompt },
                    { role: 'user', content: message }
                  ],
                  response_format: { type: 'json_object' }
                };
                
                // Only add temperature if model supports it
                const modelsWithoutTemperature = ['gpt-5-nano'];
                if (!modelsWithoutTemperature.includes(fallbackModel)) {
                  fallbackParams.temperature = 0.3;
                }
                
                const response = await this.openai.chat.completions.create(fallbackParams);
                
                console.log(`‚úÖ [AI-ANALYZE] Fallback model ${fallbackModel} worked!`);
                const rawContent = response.choices[0].message.content;
                extractedParams = JSON.parse(rawContent);
                break; // Success, exit loop
              } catch (fallbackError) {
                console.warn(`‚ùå [AI-ANALYZE] Fallback model ${fallbackModel} also failed:`, fallbackError.message);
                if (fallbackModel === fallbackModels[fallbackModels.length - 1]) {
                  // Last fallback failed, throw original error
                  throw modelError;
                }
              }
            }
          } else {
            throw modelError;
          }
        }
      } else {
        console.error('‚ùå [AI-ANALYZE] No AI provider configured!');
        throw new Error('No AI provider configured');
      }

      console.log('‚úÖ [AI-ANALYZE] Analysis complete!');
      console.log('üìä [AI-ANALYZE] Extracted params (before validation):', JSON.stringify(extractedParams, null, 2));
      
      // Step 2: Validate category against available categories
      if (extractedParams.category && categories.length > 0) {
        const categorySlug = extractedParams.category.toLowerCase();
        const validCategory = categories.find(cat => 
          cat.slug.toLowerCase() === categorySlug ||
          cat.name?.toLowerCase() === categorySlug ||
          cat.nameEn?.toLowerCase() === categorySlug ||
          cat.nameAr?.toLowerCase() === categorySlug ||
          cat.name === extractedParams.category ||
          cat.nameAr === extractedParams.category ||
          cat.nameEn?.toLowerCase() === categorySlug
        );
        
        if (validCategory) {
          // Use the exact slug from the API
          extractedParams.category = validCategory.slug;
          extractedParams.categoryValidated = true;
          console.log('‚úÖ [AI-ANALYZE] Category validated:', {
            original: extractedParams.category,
            validated: validCategory.slug,
            name: validCategory.name || validCategory.nameAr || validCategory.nameEn
          });
        } else {
          console.warn('‚ö†Ô∏è  [AI-ANALYZE] Category not found in available categories:', extractedParams.category);
          console.warn('‚ö†Ô∏è  [AI-ANALYZE] Available categories:', categories.map(c => `${c.slug} (${c.name})`).join(', '));
          // Keep the category but mark as potentially invalid - let the API handle it
          extractedParams.categoryValidated = false;
        }
      } else if (extractedParams.category && categories.length === 0) {
        console.log('‚ÑπÔ∏è  [AI-ANALYZE] Categories not available, using extracted category as-is:', extractedParams.category);
      }
      
      // Step 3: Ensure keywords are extracted from the message
      if (!extractedParams.keywords && message) {
        // If no keywords extracted but we have a message, use the message as keywords
        // But only if category is not set (general search)
        if (!extractedParams.category) {
          extractedParams.keywords = message.trim();
          console.log('üìù [AI-ANALYZE] No keywords extracted, using message as keywords:', extractedParams.keywords);
        }
      }
      
      console.log('üìä [AI-ANALYZE] Final extracted params:', JSON.stringify(extractedParams, null, 2));
      logger.info('Message analyzed successfully', { extractedParams });
      return extractedParams;

    } catch (error) {
      console.error('‚ùå [AI-ANALYZE] Error analyzing message:', {
        message: error.message,
        stack: error.stack
      });
      logger.error('Error analyzing message:', error);
      throw error;
    }
  }

  /**
   * Format search results into a user-friendly message
   * @param {Array} results - Search results
   * @param {string} language - Response language (will be detected from user message if not provided)
   * @param {string} userMessage - Optional: original user message for language detection
   * @returns {Promise<string>} Formatted message
   */
  async formatResults(results, language = 'ar', userMessage = null) {
    try {
      // Detect language from user message if provided, otherwise use provided language
      const detectedLanguage = userMessage ? detectLanguage(userMessage) : language;
      console.log('üìù [AI-FORMAT] Starting result formatting...');
      console.log('üìä [AI-FORMAT] Input:', {
        results_count: results?.length || 0,
        provided_language: language,
        detected_language: detectedLanguage,
        provider: this.provider
      });
      
      if (!results || results.length === 0) {
        console.log('‚ö†Ô∏è  [AI-FORMAT] No results to format');
        return detectedLanguage === 'ar' 
          ? 'ÿπÿ∞ÿ±ÿßŸãÿå ŸÑŸÖ ÿ£ÿ¨ÿØ ÿ£Ÿä ŸÜÿ™ÿßÿ¶ÿ¨ ÿ™ÿ∑ÿßÿ®ŸÇ ÿ®ÿ≠ÿ´ŸÉ. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ ÿ®ŸÖÿπÿßŸäŸäÿ± ŸÖÿÆÿ™ŸÑŸÅÿ©.'
          : 'Sorry, I couldn\'t find any results matching your search. Please try again with different criteria.';
      }

      // Add listing URLs and photo URLs to each result before formatting
      const enrichedResults = results.slice(0, 10).map(result => {
        const enriched = { ...result };
        
        // Add listing URL if id exists
        if (result.id) {
          enriched.listingUrl = `https://www.kasioon.com/listing/${result.id}/`;
        }
        
        // Add first photo URL if images exist
        if (result.images && Array.isArray(result.images) && result.images.length > 0) {
          // Handle both string URLs and objects with url property
          const firstImage = result.images[0];
          enriched.photoUrl = typeof firstImage === 'string' ? firstImage : (firstImage.url || firstImage);
        } else if (result.image) {
          // Fallback for single image field
          enriched.photoUrl = typeof result.image === 'string' ? result.image : (result.image.url || result.image);
        }
        
        return enriched;
      });

      // Create a more generic prompt that works for all categories
      // IMPORTANT: Always respond in the same language as the user's original message
      const systemPrompt = detectedLanguage === 'ar'
        ? `ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ÿ∞ŸÉŸä Ÿäÿ≥ÿßÿπÿØ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ŸÅŸä ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ŸÅŸä ÿ≥ŸàŸÇ kasioon.com. 

ŸÇŸÖ ÿ®ÿ™ŸÜÿ≥ŸäŸÇ ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ™ÿßŸÑŸäÿ© ÿ®ÿ¥ŸÉŸÑ Ÿàÿßÿ∂ÿ≠ Ÿàÿ¨ÿ∞ÿßÿ® ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸÅŸÇÿ∑. ÿßÿ≥ÿ™ÿ¨ÿ® ÿØÿßÿ¶ŸÖÿßŸã ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©.

ÿßÿπÿ±ÿ∂ ŸÑŸÉŸÑ ŸÜÿ™Ÿäÿ¨ÿ©:
- ÿßŸÑÿπŸÜŸàÿßŸÜ/ÿßŸÑÿßÿ≥ŸÖ
- ÿßŸÑŸÅÿ¶ÿ© (ÿ≥Ÿäÿßÿ±ÿßÿ™ÿå ÿπŸÇÿßÿ±ÿßÿ™ÿå ÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸäÿßÿ™ÿå ÿ•ŸÑÿÆ)
- ÿßŸÑÿ≥ÿπÿ± (ÿ•ŸÜ Ÿàÿ¨ÿØ)
- ÿßŸÑŸÖŸàŸÇÿπ/ÿßŸÑŸÖÿØŸäŸÜÿ© (ÿ•ŸÜ Ÿàÿ¨ÿØ)
- ÿßŸÑÿÆÿµÿßÿ¶ÿµ ÿßŸÑŸÖŸáŸÖÿ© (ÿßŸÑÿ∫ÿ±ŸÅÿå ÿßŸÑŸÖÿ≥ÿßÿ≠ÿ©ÿå ÿßŸÑÿπŸÑÿßŸÖÿ© ÿßŸÑÿ™ÿ¨ÿßÿ±Ÿäÿ©ÿå ÿ•ŸÑÿÆ)
- ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ•ÿπŸÑÿßŸÜ (listingUrl) - Ÿäÿ¨ÿ® ÿ™ÿ∂ŸÖŸäŸÜŸá ÿØÿßÿ¶ŸÖÿßŸã
- ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿµŸàÿ±ÿ© (photoUrl) - ÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖÿ™ŸàŸÅÿ±ÿßŸã

ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ•ŸäŸÖŸàÿ¨Ÿä ŸÑÿ¨ÿπŸÑ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© ÿ£ŸÉÿ´ÿ± ÿ¨ÿßÿ∞ÿ®Ÿäÿ©. ŸÉŸÜ Ÿàÿßÿ∂ÿ≠ÿßŸã ŸàŸÖÿÆÿ™ÿµÿ±ÿßŸã. ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ™ÿ∂ŸÖŸäŸÜ ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ•ÿπŸÑÿßŸÜ ŸÑŸÉŸÑ ŸÜÿ™Ÿäÿ¨ÿ©.`
        : `You are an AI assistant helping users search for products on kasioon.com marketplace. 

Format the following search results in a clear and attractive way in English only. Always respond in English.

For each result, show:
- Title/Name
- Category (vehicles, real estate, electronics, etc.)
- Price (if available)
- Location/City (if available)
- Important attributes (rooms, area, brand, etc.)
- Listing URL (listingUrl) - MUST be included for every result
- Photo URL (photoUrl) - if available

Use emojis to make the message more engaging. Be clear and concise. Make sure to include the listing URL for every result.`;

      const resultsData = JSON.stringify(enrichedResults, null, 2); // Limit to top 10 results
      console.log('üì¶ [AI-FORMAT] Results data size:', resultsData.length, 'characters');

      let formattedMessage;

      if (this.provider === 'anthropic' && this.anthropic) {
        console.log('üîµ [AI-FORMAT] Using Anthropic Claude...');
        console.log('ü§ñ [AI-FORMAT] Model:', this.anthropicModel);
        
        const response = await this.anthropic.messages.create({
          model: this.anthropicModel,
          max_tokens: 2048,
          messages: [
            {
              role: 'user',
              content: `${systemPrompt}\n\nSearch Results:\n${resultsData}`
            }
          ]
        });

        console.log('‚úÖ [AI-FORMAT] Anthropic response received');
        formattedMessage = response.content[0].text;

      } else if (this.openai) {
        console.log('üü¢ [AI-FORMAT] Using OpenAI GPT...');
        console.log('ü§ñ [AI-FORMAT] Model:', this.openaiModel);
        
        try {
          const response = await this.openai.chat.completions.create({
            model: this.openaiModel,
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: `Search Results:\n${resultsData}` }
            ],
            temperature: 0.7
          });

          console.log('‚úÖ [AI-FORMAT] OpenAI response received');
          formattedMessage = response.choices[0].message.content;
        } catch (modelError) {
          // Check if it's a temperature error - retry without temperature
          if (modelError.message && modelError.message.includes('temperature') && 
              modelError.message.includes('does not support')) {
            console.warn('‚ö†Ô∏è  [AI-FORMAT] Temperature not supported, retrying without temperature...');
            try {
              const response = await this.openai.chat.completions.create({
                model: this.openaiModel,
                messages: [
                  { role: 'system', content: systemPrompt },
                  { role: 'user', content: `Search Results:\n${resultsData}` }
                ]
                // No temperature parameter
              });
              
              console.log('‚úÖ [AI-FORMAT] Retry without temperature succeeded!');
              formattedMessage = response.choices[0].message.content;
            } catch (retryError) {
              console.error('‚ùå [AI-FORMAT] Retry also failed:', retryError.message);
              throw modelError; // Throw original error
            }
          }
          // If model access error, try fallback models
          else if (modelError.message && modelError.message.includes('does not have access to model')) {
            console.warn('‚ö†Ô∏è  [AI-FORMAT] Model access error, trying fallback models...');
            const fallbackModels = ['gpt-5-mini', 'gpt-3.5-turbo', 'gpt-4'];
            
            for (const fallbackModel of fallbackModels) {
              if (fallbackModel === this.openaiModel) continue; // Skip if already tried
              
              try {
                console.log(`üîÑ [AI-FORMAT] Trying fallback model: ${fallbackModel}`);
                const response = await this.openai.chat.completions.create({
                  model: fallbackModel,
                  messages: [
                    { role: 'system', content: systemPrompt },
                    { role: 'user', content: `Search Results:\n${resultsData}` }
                  ],
                  temperature: 0.7
                });
                
                console.log(`‚úÖ [AI-FORMAT] Fallback model ${fallbackModel} worked!`);
                formattedMessage = response.choices[0].message.content;
                break; // Success, exit loop
              } catch (fallbackError) {
                console.warn(`‚ùå [AI-FORMAT] Fallback model ${fallbackModel} also failed:`, fallbackError.message);
                if (fallbackModel === fallbackModels[fallbackModels.length - 1]) {
                  // Last fallback failed, throw original error
                  throw modelError;
                }
              }
            }
          } else {
            throw modelError;
          }
        }
      }

      console.log('‚úÖ [AI-FORMAT] Formatting complete!');
      console.log('üìÑ [AI-FORMAT] Formatted message length:', formattedMessage?.length || 0);
      return formattedMessage;

    } catch (error) {
      console.error('‚ùå [AI-FORMAT] Error formatting results:', {
        message: error.message,
        stack: error.stack
      });
      console.log('üîÑ [AI-FORMAT] Falling back to simple formatting...');
      logger.error('Error formatting results:', error);
      // Fallback to simple formatting
      const fallbackLanguage = userMessage ? detectLanguage(userMessage) : language;
      return this.simpleFormat(results, fallbackLanguage);
    }
  }

  /**
   * Simple fallback formatting
   */
  simpleFormat(results, language = 'ar') {
    if (language === 'ar') {
      let message = `üöó Ÿàÿ¨ÿØÿ™ ${results.length} ŸÜÿ™Ÿäÿ¨ÿ©:\n\n`;
      results.slice(0, 10).forEach((item, index) => {
        const title = item.title || item.name || `${item.brand || ''} ${item.model || ''}`.trim() || 'ÿ•ÿπŸÑÿßŸÜ';
        message += `${index + 1}. ${title}\n`;
        
        if (item.brand || item.model) {
          message += `   üè∑Ô∏è ${item.brand || ''} ${item.model || ''}\n`;
        }
        if (item.year) {
          message += `   üìÖ ÿßŸÑÿ≥ŸÜÿ©: ${item.year}\n`;
        }
        if (item.attributes?.price || item.price) {
          message += `   üí∞ ÿßŸÑÿ≥ÿπÿ±: ${item.attributes?.price || item.price}\n`;
        }
        if (item.location?.cityName || item.city) {
          message += `   üìç ÿßŸÑŸÖÿØŸäŸÜÿ©: ${item.location?.cityName || item.city}\n`;
        }
        
        // Add listing URL
        if (item.id) {
          message += `   üîó ÿßŸÑÿ±ÿßÿ®ÿ∑: https://www.kasioon.com/listing/${item.id}/\n`;
        }
        
        // Add photo URL if available
        if (item.images && Array.isArray(item.images) && item.images.length > 0) {
          const firstImage = item.images[0];
          const photoUrl = typeof firstImage === 'string' ? firstImage : (firstImage.url || firstImage);
          message += `   üì∑ ÿßŸÑÿµŸàÿ±ÿ©: ${photoUrl}\n`;
        } else if (item.image) {
          const photoUrl = typeof item.image === 'string' ? item.image : (item.image.url || item.image);
          message += `   üì∑ ÿßŸÑÿµŸàÿ±ÿ©: ${photoUrl}\n`;
        }
        
        message += `\n`;
      });
      return message;
    } else {
      let message = `üöó Found ${results.length} results:\n\n`;
      results.slice(0, 10).forEach((item, index) => {
        const title = item.title || item.name || `${item.brand || ''} ${item.model || ''}`.trim() || 'Listing';
        message += `${index + 1}. ${title}\n`;
        
        if (item.brand || item.model) {
          message += `   üè∑Ô∏è ${item.brand || ''} ${item.model || ''}\n`;
        }
        if (item.year) {
          message += `   üìÖ Year: ${item.year}\n`;
        }
        if (item.attributes?.price || item.price) {
          message += `   üí∞ Price: ${item.attributes?.price || item.price}\n`;
        }
        if (item.location?.cityName || item.city) {
          message += `   üìç City: ${item.location?.cityName || item.city}\n`;
        }
        
        // Add listing URL
        if (item.id) {
          message += `   üîó Link: https://www.kasioon.com/listing/${item.id}/\n`;
        }
        
        // Add photo URL if available
        if (item.images && Array.isArray(item.images) && item.images.length > 0) {
          const firstImage = item.images[0];
          const photoUrl = typeof firstImage === 'string' ? firstImage : (firstImage.url || firstImage);
          message += `   üì∑ Photo: ${photoUrl}\n`;
        } else if (item.image) {
          const photoUrl = typeof item.image === 'string' ? item.image : (item.image.url || item.image);
          message += `   üì∑ Photo: ${photoUrl}\n`;
        }
        
        message += `\n`;
      });
      return message;
    }
  }

  /**
   * Transcribe voice message to text
   * @param {Buffer} audioBuffer - Audio file buffer
   * @returns {Promise<string>} Transcribed text
   */
  async transcribeAudio(audioBuffer) {
    try {
      if (!this.openai) {
        throw new Error('OpenAI is required for audio transcription');
      }

      // Create a File-like object from buffer
      const file = new File([audioBuffer], 'audio.ogg', { type: 'audio/ogg' });

      const response = await this.openai.audio.transcriptions.create({
        file: file,
        model: 'whisper-1',
        language: 'ar' // Arabic by default, Whisper auto-detects
      });

      logger.info('Audio transcribed successfully');
      return response.text;

    } catch (error) {
      logger.error('Error transcribing audio:', error);
      throw error;
    }
  }
}

module.exports = new AIAgent();

